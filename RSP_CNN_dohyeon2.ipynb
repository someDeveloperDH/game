{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/someDeveloperDH/game/blob/main/RSP_CNN_dohyeon2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A60ExDzbg8h1",
      "metadata": {
        "id": "A60ExDzbg8h1"
      },
      "source": [
        "참고 블로그\n",
        "\n",
        "https://medium.com/@msmapark2/vgg16-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-very-deep-convolutional-networks-for-large-scale-image-recognition-6f748235242a\n",
        "\n",
        "https://blog.naver.com/2hannseok/223229158970\n",
        "\n",
        "https://diseny.tistory.com/entry/%ED%98%BC%EB%8F%99%ED%96%89%EB%A0%ACconfusion-matrix?category=906035\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VRXmYfsvdliV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRXmYfsvdliV",
        "outputId": "a4cda004-37ee-4b4b-a42e-56428059d2ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C9NRKwzldvEg",
      "metadata": {
        "id": "C9NRKwzldvEg"
      },
      "outputs": [],
      "source": [
        "#필요한거 import\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dos-AYhseCS9",
      "metadata": {
        "id": "dos-AYhseCS9"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/RPS'  # 필요시 경로 수정\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# 이미지 크기 128x128로 설정 (100x100도 해봤는데 정확도 30퍼나옴..)\n",
        "img_size = (128, 128)\n",
        "\n",
        "# 데이터 증강\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QX_86j9JeLxq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX_86j9JeLxq",
        "outputId": "da2007ab-dd86-4373-aeef-66f53d297819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1950 images belonging to 3 classes.\n",
            "Found 270 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "#generator 설정(_g)\n",
        "train_g = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=16,  # 배치 크기 16으로 함\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_g = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r9XoI2B_fGNn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9XoI2B_fGNn",
        "outputId": "78b98075-75d9-40d6-e6c7-520e5a62009e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 데이터셋에 맞게 스텝 조정\n",
        "epochstep = train_g.samples // train_g.batch_size\n",
        "val_step = val_g.samples // val_g.batch_size\n",
        "\n",
        "# VGG16 모델 사용\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
        "\n",
        "#모든 레이어 freeze\n",
        "for layer in vgg_base.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0BwYm-EqFlvk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BwYm-EqFlvk",
        "outputId": "be852be9-d531-401b-bf4e-4755725440c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "121/121 [==============================] - 37s 299ms/step - loss: 1.1587 - accuracy: 0.4105 - val_loss: 0.8617 - val_accuracy: 0.6875\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 22s 176ms/step - loss: 0.9142 - accuracy: 0.5760 - val_loss: 0.7235 - val_accuracy: 0.7891\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 22s 181ms/step - loss: 0.7848 - accuracy: 0.6587 - val_loss: 0.6299 - val_accuracy: 0.8281\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 21s 172ms/step - loss: 0.7163 - accuracy: 0.7208 - val_loss: 0.5655 - val_accuracy: 0.8555\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 22s 180ms/step - loss: 0.6505 - accuracy: 0.7554 - val_loss: 0.5261 - val_accuracy: 0.8555\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 23s 187ms/step - loss: 0.5901 - accuracy: 0.7813 - val_loss: 0.4647 - val_accuracy: 0.8906\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 21s 176ms/step - loss: 0.5532 - accuracy: 0.8020 - val_loss: 0.4305 - val_accuracy: 0.9062\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 20s 166ms/step - loss: 0.5229 - accuracy: 0.8066 - val_loss: 0.3938 - val_accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 23s 189ms/step - loss: 0.4929 - accuracy: 0.8170 - val_loss: 0.3793 - val_accuracy: 0.9023\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 21s 172ms/step - loss: 0.4665 - accuracy: 0.8382 - val_loss: 0.3624 - val_accuracy: 0.8945\n",
            "17/17 [==============================] - 2s 64ms/step\n",
            "[[31 37 22]\n",
            " [27 36 27]\n",
            " [28 31 31]]\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(vgg_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),  # 학습률을 줄임\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/RPS/model_checkpoint.keras', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "history = model.fit(\n",
        "    train_g,\n",
        "    steps_per_epoch=epochstep,\n",
        "    epochs=10,\n",
        "    validation_data=val_g,\n",
        "    validation_steps=val_step,\n",
        "    callbacks=[early_stopping, checkpoint]\n",
        ")\n",
        "\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "Y_pred = model.predict(val_g, val_g.samples // val_g.batch_size + 1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "cm = confusion_matrix(val_g.classes, y_pred)\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TKOgxEe5Uj15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKOgxEe5Uj15",
        "outputId": "36247dc5-d73f-44fa-f7c3-6f078d51cff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Found 1950 images belonging to 3 classes.\n",
            "Found 270 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 602s 10s/step - loss: 0.8784 - accuracy: 0.5923 - val_loss: 0.4795 - val_accuracy: 0.8125\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 21s 348ms/step - loss: 0.5553 - accuracy: 0.7737 - val_loss: 0.3157 - val_accuracy: 0.9023\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 21s 347ms/step - loss: 0.4674 - accuracy: 0.8227 - val_loss: 0.2970 - val_accuracy: 0.8867\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 21s 343ms/step - loss: 0.3975 - accuracy: 0.8472 - val_loss: 0.2405 - val_accuracy: 0.9375\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 22s 352ms/step - loss: 0.3576 - accuracy: 0.8655 - val_loss: 0.2411 - val_accuracy: 0.9141\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 20s 339ms/step - loss: 0.3611 - accuracy: 0.8577 - val_loss: 0.1940 - val_accuracy: 0.9375\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 22s 365ms/step - loss: 0.3304 - accuracy: 0.8655 - val_loss: 0.1927 - val_accuracy: 0.9375\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 22s 362ms/step - loss: 0.3293 - accuracy: 0.8827 - val_loss: 0.1624 - val_accuracy: 0.9570\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 21s 344ms/step - loss: 0.2975 - accuracy: 0.8879 - val_loss: 0.1579 - val_accuracy: 0.9609\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 21s 359ms/step - loss: 0.2961 - accuracy: 0.8910 - val_loss: 0.1806 - val_accuracy: 0.9531\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 20s 329ms/step - loss: 0.2867 - accuracy: 0.8921 - val_loss: 0.1481 - val_accuracy: 0.9570\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 22s 357ms/step - loss: 0.2605 - accuracy: 0.9030 - val_loss: 0.1547 - val_accuracy: 0.9453\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 19s 321ms/step - loss: 0.2600 - accuracy: 0.9072 - val_loss: 0.2019 - val_accuracy: 0.9062\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 21s 344ms/step - loss: 0.2417 - accuracy: 0.9119 - val_loss: 0.1397 - val_accuracy: 0.9453\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 21s 342ms/step - loss: 0.2701 - accuracy: 0.8957 - val_loss: 0.1588 - val_accuracy: 0.9453\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 20s 338ms/step - loss: 0.2376 - accuracy: 0.9119 - val_loss: 0.1336 - val_accuracy: 0.9531\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 21s 355ms/step - loss: 0.2154 - accuracy: 0.9275 - val_loss: 0.1287 - val_accuracy: 0.9570\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 21s 343ms/step - loss: 0.2110 - accuracy: 0.9260 - val_loss: 0.1091 - val_accuracy: 0.9648\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 20s 327ms/step - loss: 0.2268 - accuracy: 0.9171 - val_loss: 0.1197 - val_accuracy: 0.9688\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 20s 339ms/step - loss: 0.2031 - accuracy: 0.9286 - val_loss: 0.1206 - val_accuracy: 0.9609\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 20s 326ms/step - loss: 0.2103 - accuracy: 0.9234 - val_loss: 0.1262 - val_accuracy: 0.9609\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 23s 376ms/step - loss: 0.2104 - accuracy: 0.9228 - val_loss: 0.1058 - val_accuracy: 0.9766\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 21s 359ms/step - loss: 0.2170 - accuracy: 0.9213 - val_loss: 0.1157 - val_accuracy: 0.9727\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 22s 358ms/step - loss: 0.1890 - accuracy: 0.9327 - val_loss: 0.1213 - val_accuracy: 0.9570\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 20s 326ms/step - loss: 0.2008 - accuracy: 0.9307 - val_loss: 0.1060 - val_accuracy: 0.9688\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 20s 340ms/step - loss: 0.1949 - accuracy: 0.9244 - val_loss: 0.1273 - val_accuracy: 0.9648\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 21s 355ms/step - loss: 0.1802 - accuracy: 0.9322 - val_loss: 0.1033 - val_accuracy: 0.9688\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 20s 341ms/step - loss: 0.1905 - accuracy: 0.9291 - val_loss: 0.0992 - val_accuracy: 0.9766\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 22s 359ms/step - loss: 0.1986 - accuracy: 0.9249 - val_loss: 0.1010 - val_accuracy: 0.9609\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 19s 322ms/step - loss: 0.2008 - accuracy: 0.9208 - val_loss: 0.1338 - val_accuracy: 0.9648\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 19s 321ms/step - loss: 0.1915 - accuracy: 0.9286 - val_loss: 0.1115 - val_accuracy: 0.9609\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 20s 337ms/step - loss: 0.1700 - accuracy: 0.9421 - val_loss: 0.0989 - val_accuracy: 0.9648\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 20s 327ms/step - loss: 0.1654 - accuracy: 0.9395 - val_loss: 0.1155 - val_accuracy: 0.9688\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 20s 336ms/step - loss: 0.1577 - accuracy: 0.9494 - val_loss: 0.1034 - val_accuracy: 0.9766\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 19s 323ms/step - loss: 0.1610 - accuracy: 0.9411 - val_loss: 0.1108 - val_accuracy: 0.9609\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 20s 334ms/step - loss: 0.1739 - accuracy: 0.9395 - val_loss: 0.1042 - val_accuracy: 0.9688\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 21s 343ms/step - loss: 0.1794 - accuracy: 0.9348 - val_loss: 0.1547 - val_accuracy: 0.9375\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 20s 329ms/step - loss: 0.1571 - accuracy: 0.9499 - val_loss: 0.0933 - val_accuracy: 0.9609\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 22s 368ms/step - loss: 0.1686 - accuracy: 0.9348 - val_loss: 0.0866 - val_accuracy: 0.9727\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 22s 360ms/step - loss: 0.1476 - accuracy: 0.9442 - val_loss: 0.0865 - val_accuracy: 0.9805\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 20s 334ms/step - loss: 0.1512 - accuracy: 0.9499 - val_loss: 0.0848 - val_accuracy: 0.9805\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 21s 340ms/step - loss: 0.1404 - accuracy: 0.9494 - val_loss: 0.1613 - val_accuracy: 0.9375\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 21s 357ms/step - loss: 0.1701 - accuracy: 0.9348 - val_loss: 0.0840 - val_accuracy: 0.9766\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 20s 342ms/step - loss: 0.1447 - accuracy: 0.9499 - val_loss: 0.0721 - val_accuracy: 0.9844\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 19s 318ms/step - loss: 0.1482 - accuracy: 0.9479 - val_loss: 0.0986 - val_accuracy: 0.9648\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 22s 362ms/step - loss: 0.1784 - accuracy: 0.9333 - val_loss: 0.0830 - val_accuracy: 0.9727\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 20s 332ms/step - loss: 0.1530 - accuracy: 0.9473 - val_loss: 0.0853 - val_accuracy: 0.9727\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 21s 351ms/step - loss: 0.1558 - accuracy: 0.9416 - val_loss: 0.0873 - val_accuracy: 0.9727\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 21s 346ms/step - loss: 0.1567 - accuracy: 0.9458 - val_loss: 0.0792 - val_accuracy: 0.9766\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 20s 336ms/step - loss: 0.1397 - accuracy: 0.9505 - val_loss: 0.0901 - val_accuracy: 0.9727\n",
            "9/9 [==============================] - 3s 344ms/step\n",
            "[[32 32 26]\n",
            " [29 29 32]\n",
            " [32 31 27]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/RPS'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# 이미지 크기 및 데이터 증강\n",
        "img_size = (128, 128)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 데이터 생성기 설정\n",
        "train_g = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,  # 배치 크기 증가\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_g = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# VGG16 모델 설정\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
        "for layer in vgg_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 모델 구성\n",
        "model = Sequential()\n",
        "model.add(vgg_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))  # 은닉층 크기 증가\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-4),  # 학습률 조정\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/RPS/model_checkpoint.keras', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_g,\n",
        "    steps_per_epoch=train_g.samples // train_g.batch_size,\n",
        "    epochs=50,  # 에포크 증가\n",
        "    validation_data=val_g,\n",
        "    validation_steps=val_g.samples // val_g.batch_size,\n",
        "    callbacks=[early_stopping, checkpoint]\n",
        ")\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "Y_pred = model.predict(val_g, val_g.samples // val_g.batch_size + 1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "cm = confusion_matrix(val_g.classes, y_pred)\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V_Yk_sHCcDd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_Yk_sHCcDd9",
        "outputId": "6457b8c5-48b2-4483-a5e8-f582af4c3863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 32.59%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 테스트 데이터 정확도 계산\n",
        "accuracy = accuracy_score(val_g.classes, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H8xDHFfdccxu",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8xDHFfdccxu",
        "outputId": "42d47846-d5e8-4129-e7f9-4cc1f0cfb177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 1950 images belonging to 3 classes.\n",
            "Found 270 images belonging to 3 classes.\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 24s 379ms/step - loss: 1.2825 - accuracy: 0.3670 - val_loss: 0.9402 - val_accuracy: 0.6445\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 24s 396ms/step - loss: 1.1628 - accuracy: 0.4176 - val_loss: 0.8225 - val_accuracy: 0.7422\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 23s 376ms/step - loss: 1.0209 - accuracy: 0.5005 - val_loss: 0.7322 - val_accuracy: 0.7773\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 24s 392ms/step - loss: 0.9507 - accuracy: 0.5308 - val_loss: 0.6734 - val_accuracy: 0.8047\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 23s 381ms/step - loss: 0.8969 - accuracy: 0.5746 - val_loss: 0.6123 - val_accuracy: 0.8555\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 23s 382ms/step - loss: 0.8323 - accuracy: 0.6189 - val_loss: 0.5852 - val_accuracy: 0.8320\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 21s 347ms/step - loss: 0.7760 - accuracy: 0.6611 - val_loss: 0.5327 - val_accuracy: 0.8594\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 22s 376ms/step - loss: 0.7590 - accuracy: 0.6637 - val_loss: 0.5010 - val_accuracy: 0.8789\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 23s 386ms/step - loss: 0.7334 - accuracy: 0.6809 - val_loss: 0.4795 - val_accuracy: 0.8789\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 21s 358ms/step - loss: 0.6975 - accuracy: 0.7101 - val_loss: 0.4504 - val_accuracy: 0.8984\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 23s 382ms/step - loss: 0.6809 - accuracy: 0.7143 - val_loss: 0.4428 - val_accuracy: 0.8789\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 23s 386ms/step - loss: 0.6712 - accuracy: 0.7320 - val_loss: 0.4331 - val_accuracy: 0.8867\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 22s 370ms/step - loss: 0.6410 - accuracy: 0.7398 - val_loss: 0.4102 - val_accuracy: 0.8828\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 21s 357ms/step - loss: 0.6168 - accuracy: 0.7576 - val_loss: 0.3968 - val_accuracy: 0.8906\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 22s 367ms/step - loss: 0.6095 - accuracy: 0.7602 - val_loss: 0.3728 - val_accuracy: 0.8984\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 21s 339ms/step - loss: 0.6179 - accuracy: 0.7503 - val_loss: 0.3690 - val_accuracy: 0.8984\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 23s 372ms/step - loss: 0.6052 - accuracy: 0.7419 - val_loss: 0.3624 - val_accuracy: 0.9062\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 21s 358ms/step - loss: 0.5915 - accuracy: 0.7675 - val_loss: 0.3502 - val_accuracy: 0.9023\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 21s 351ms/step - loss: 0.5833 - accuracy: 0.7659 - val_loss: 0.3386 - val_accuracy: 0.9180\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 20s 329ms/step - loss: 0.5634 - accuracy: 0.7706 - val_loss: 0.3389 - val_accuracy: 0.9062\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 21s 354ms/step - loss: 0.5502 - accuracy: 0.7821 - val_loss: 0.3139 - val_accuracy: 0.9258\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 21s 345ms/step - loss: 0.5713 - accuracy: 0.7550 - val_loss: 0.3195 - val_accuracy: 0.9062\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 22s 361ms/step - loss: 0.5275 - accuracy: 0.7868 - val_loss: 0.3061 - val_accuracy: 0.9219\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 22s 366ms/step - loss: 0.5282 - accuracy: 0.7930 - val_loss: 0.3049 - val_accuracy: 0.9180\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 21s 340ms/step - loss: 0.5321 - accuracy: 0.7836 - val_loss: 0.3020 - val_accuracy: 0.9023\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 22s 361ms/step - loss: 0.5047 - accuracy: 0.8024 - val_loss: 0.2971 - val_accuracy: 0.9141\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 21s 334ms/step - loss: 0.5332 - accuracy: 0.7842 - val_loss: 0.2945 - val_accuracy: 0.9062\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 20s 329ms/step - loss: 0.5277 - accuracy: 0.7862 - val_loss: 0.2874 - val_accuracy: 0.9102\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 20s 334ms/step - loss: 0.5157 - accuracy: 0.7888 - val_loss: 0.2965 - val_accuracy: 0.8945\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 20s 331ms/step - loss: 0.4942 - accuracy: 0.8102 - val_loss: 0.2742 - val_accuracy: 0.9102\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 22s 355ms/step - loss: 0.4994 - accuracy: 0.8034 - val_loss: 0.2612 - val_accuracy: 0.9180\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 23s 377ms/step - loss: 0.4988 - accuracy: 0.8024 - val_loss: 0.2538 - val_accuracy: 0.9414\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 21s 350ms/step - loss: 0.4692 - accuracy: 0.8196 - val_loss: 0.2662 - val_accuracy: 0.9102\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 22s 363ms/step - loss: 0.4839 - accuracy: 0.8107 - val_loss: 0.2694 - val_accuracy: 0.9141\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 20s 341ms/step - loss: 0.4809 - accuracy: 0.8107 - val_loss: 0.2542 - val_accuracy: 0.9375\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 22s 369ms/step - loss: 0.4831 - accuracy: 0.8081 - val_loss: 0.2530 - val_accuracy: 0.9219\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 22s 360ms/step - loss: 0.4923 - accuracy: 0.8019 - val_loss: 0.2594 - val_accuracy: 0.9219\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 22s 371ms/step - loss: 0.4644 - accuracy: 0.8175 - val_loss: 0.2485 - val_accuracy: 0.9102\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 21s 351ms/step - loss: 0.4702 - accuracy: 0.8149 - val_loss: 0.2587 - val_accuracy: 0.9023\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 20s 328ms/step - loss: 0.4599 - accuracy: 0.8285 - val_loss: 0.2424 - val_accuracy: 0.9219\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 22s 360ms/step - loss: 0.4682 - accuracy: 0.8154 - val_loss: 0.2477 - val_accuracy: 0.9141\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 20s 331ms/step - loss: 0.4447 - accuracy: 0.8264 - val_loss: 0.2308 - val_accuracy: 0.9219\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 22s 361ms/step - loss: 0.4760 - accuracy: 0.8165 - val_loss: 0.2292 - val_accuracy: 0.9375\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 20s 328ms/step - loss: 0.4443 - accuracy: 0.8248 - val_loss: 0.2372 - val_accuracy: 0.9141\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 20s 339ms/step - loss: 0.4746 - accuracy: 0.8066 - val_loss: 0.2322 - val_accuracy: 0.9336\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 21s 341ms/step - loss: 0.4661 - accuracy: 0.8071 - val_loss: 0.2248 - val_accuracy: 0.9336\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 22s 364ms/step - loss: 0.4332 - accuracy: 0.8279 - val_loss: 0.2187 - val_accuracy: 0.9336\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 20s 336ms/step - loss: 0.4322 - accuracy: 0.8358 - val_loss: 0.2277 - val_accuracy: 0.9180\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 19s 318ms/step - loss: 0.4426 - accuracy: 0.8233 - val_loss: 0.2277 - val_accuracy: 0.9141\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 21s 347ms/step - loss: 0.4323 - accuracy: 0.8321 - val_loss: 0.2135 - val_accuracy: 0.9414\n",
            "9/9 [==============================] - 1s 108ms/step\n",
            "Confusion Matrix:\n",
            "[[34 35 21]\n",
            " [24 27 39]\n",
            " [27 34 29]]\n",
            "Accuracy: 33.33%\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/RPS'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# 이미지 크기 및 데이터 증강\n",
        "img_size = (128, 128)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 데이터 생성기 설정\n",
        "train_g = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_g = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# VGG16 모델 설정\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
        "for layer in vgg_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 모델 구성\n",
        "model = Sequential()\n",
        "model.add(vgg_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.6))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/RPS/model_checkpoint.keras', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_g,\n",
        "    steps_per_epoch=train_g.samples // train_g.batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=val_g,\n",
        "    validation_steps=val_g.samples // val_g.batch_size,\n",
        "    callbacks=[early_stopping, checkpoint]\n",
        ")\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "Y_pred = model.predict(val_g, val_g.samples // val_g.batch_size + 1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "cm = confusion_matrix(val_g.classes, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 테스트 데이터 정확도 계산\n",
        "accuracy = accuracy_score(val_g.classes, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/RPS'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# 이미지 크기 및 데이터 증강\n",
        "img_size = (128, 128)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 데이터 생성기 설정\n",
        "train_g = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_g = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# ResNet50 모델 설정\n",
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
        "for layer in resnet_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 모델 구성\n",
        "model = Sequential()\n",
        "model.add(resnet_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.6))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/RPS/model_checkpoint.keras', save_best_only=True, monitor='val_loss')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_g,\n",
        "    steps_per_epoch=train_g.samples // train_g.batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=val_g,\n",
        "    validation_steps=val_g.samples // val_g.batch_size,\n",
        "    callbacks=[early_stopping, checkpoint, reduce_lr]\n",
        ")\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "Y_pred = model.predict(val_g, val_g.samples // val_g.batch_size + 1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "cm = confusion_matrix(val_g.classes, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 테스트 데이터 정확도 계산\n",
        "accuracy = accuracy_score(val_g.classes, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "vsgTOEt3U2Gi",
        "outputId": "787985a4-584b-4bcb-d522-92a11024ecda"
      },
      "id": "vsgTOEt3U2Gi",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-842fb541d6cc>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 구글 드라이브 마운트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 경로 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}